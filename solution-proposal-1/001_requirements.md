# Requirements for the Kafka Transaction Insight System

## 1. Overview

This document outlines the functional and non-functional requirements for a system designed to provide end-to-end visibility into Kafka-based business transactions. The system will correlate low-level Kafka transaction states with high-level business workflow events to provide a unified view for developers, SREs, and business analysts.

## 2. Functional Requirements

### 2.1. Data Ingestion and Correlation
- **FR1.1:** The system MUST ingest transaction state data from the Kafka broker's transaction coordinator, including transaction status (e.g., `Ongoing`, `PrepareCommit`, `Aborted`) and associated metadata (`producerId`, `epoch`).
- **FR1.2:** The system MUST ingest business workflow events from designated Kafka topics. These events must include a unique business transaction ID (`txn_id`) for correlation.
- **FR1.3:** The system MUST ingest consumer group lag information and topic end-offsets from a monitoring tool like `kminion` or an equivalent.
- **FR1.4:** The system MUST correlate the ingested data streams to create a unified view of each business transaction, linking the `txn_id` to the corresponding `producerId` and transaction state.

### 2.2. State Management and Analysis
- **FR2.1:** The system MUST maintain a stateful representation of each business transaction, tracking its lifecycle from `Open` to `Closed` or `Aborted`.
- **FR2.2:** The system MUST define and track the following transaction states:
    - `Open`: A business transaction has started, and the corresponding Kafka transaction is ongoing.
    - `TentativelyClosed`: The business logic has completed, but the Kafka transaction commit has not yet been confirmed.
    - `Closed`: The Kafka transaction has been successfully committed.
    - `Aborted`: The Kafka transaction was aborted.
    - `Stuck`: An `Open` transaction has exceeded a configurable time threshold without any activity.
- **FR2.3:** The system MUST calculate key performance indicators (KPIs) for each transaction, including `duration_ms` and `open_age_ms`.
- **FR2.4:** The system MUST detect and flag outlier transactions, defined as those with inter-step delays exceeding a configurable threshold (e.g., 15 seconds).

### 2.3. Data Exposure and Visualization
- **FR3.1:** The system MUST expose the collected and correlated data via a Prometheus-compatible `/metrics` endpoint.
- **FR3.2:** The Prometheus metrics MUST include gauges for open/stuck transactions, counters for closed/aborted transactions, and histograms for transaction durations and inter-step gaps.
- **FR3.3:** The system MUST provide a mechanism to visualize the data, preferably through pre-built Grafana dashboards.
- **FR3.4:** The Grafana dashboards MUST include panels for:
    - Real-time monitoring of open transactions and their age.
    - Commit vs. abort rates.
    - p99 transaction latency.
    - Consumer lag for validator groups.
    - Correlation between business transaction outliers and infrastructure-level anomalies.

### 2.4. Alerting
- **FR4.1:** The system MUST support configurable alerts based on the collected metrics.
- **FR4.2:** The system MUST provide pre-defined Alertmanager rules for critical conditions, including:
    - Stuck transactions exceeding a defined age threshold.
    - A significant spike in the rate of aborted transactions.
    - High commit visibility lag.

### 2.5. Benchmarking and Validation
- **FR5.1:** The system MUST provide a mechanism to generate a "ground truth" performance benchmark. This benchmark report MUST be generated by analyzing the output of the event simulator directly (e.g., from the `events.jsonl` file).
- **FR5.2:** This ground truth report will serve as a baseline to be compared against the live metrics collected by the Transaction Aggregator. The difference between the benchmark and the live metrics will be used to quantify the overhead of the Kafka infrastructure.

### 2.6. Reproducible Scenario Replay
- **FR6.1:** The system MUST provide a mechanism to replay a persisted scenario (`events.jsonl` file) to a Kafka cluster.
- **FR6.2:** The replay mechanism MUST preserve the original timing and delays between events to ensure a faithful reproduction of the workload.
- **FR6.3:** The replay mechanism SHOULD allow for adjusting the replay speed (e.g., faster or slower) via a speed factor.

## 3. Non-Functional Requirements

### 3.1. Performance and Scalability
- **NFR1.1:** The system MUST be able to handle a high volume of events from a production Kafka cluster without introducing significant performance overhead.
- **NFR1.2:** The data ingestion and processing pipeline MUST have a low latency, providing near real-time visibility into transaction states.

### 3.2. Reliability and Availability
- **NFR2.1:** The system's components MUST be designed for high availability to ensure continuous monitoring.
- **NFR2.2:** The system MUST be resilient to transient failures in the Kafka cluster or its own components.

### 3.3. Deployment and Configuration
- **NFR3.1:** The system MUST be deployable as a set of containerized services (e.g., using Docker and Helm).
- **NFR3.2:** All system parameters, including Kafka connection details, topic names, and alerting thresholds, MUST be configurable.

### 3.4. Security
- **NFR4.1:** The system MUST support secure connections to the Kafka cluster (e.g., via SASL/TLS).
- **NFR4.2:** The system should operate with the minimum required permissions (read-only where possible).

### 3.5. Testability
- **NFR5.1:** The system MUST be testable using a simulated event stream, allowing for the validation of its correlation and analysis logic under controlled conditions.
